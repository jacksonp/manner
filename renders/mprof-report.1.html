<!DOCTYPE html>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="man-page-info" data-extra1="" data-extra2="" data-extra3="">
<title>mprof-report</title>
<h1>mprof-report</h1>
<section>
  <h2>The Mono log profiler</h2>
  <p>The Mono <em>log</em> profiler can be used to collect a lot of information about a program running in the Mono runtime. This data can be used (both while the process is running and later) to do analyses of the program behaviour, determine resource usage, performance issues or even look for particular execution patterns.
  <p>This is accomplished by logging the events provided by the Mono runtime through the profiling interface and periodically writing them to a file which can be later inspected with the command line <em>mprof-report</em> program or with a GUI (not developed yet).
  <p>The events collected include (among others):
  <ul class="indent-2">
    <li>method enter and leave
    <li>object allocation
    <li>garbage collection
    <li>JIT compilation
    <li>metadata loading
    <li>lock contention
    <li>exceptions
  </ul>
  <p>In addition, the profiler can periodically collect info about all the objects present in the heap at the end of a garbage collection (this is called heap shot and currently implemented only for the sgen garbage collector). Another available profiler mode is the <em>sampling</em> or <em>statistical</em> mode: periodically the program is sampled and the information about what the program was busy with is saved. This allows to get information about the program behaviour without degrading its performance too much (usually less than 10%).
  <section>
    <h3>Basic profiler usage</h3>
    <p>The simpler way to use the profiler is the following:
    <p><strong>mono&nbsp;--profile=log&nbsp;program.exe</strong>
    <p>At the end of the execution the file <em>output.mlpd</em> will be found in the current directory. A summary report of the data can be printed by running:
    <p><strong>mprof-report&nbsp;output.mlpd</strong>
    <p>With this invocation a huge amount of data is collected about the program execution and collecting and saving this data can significantly slow down program execution. If saving the profiling data is not needed, a report can be generated directly with:
    <p><strong>mono&nbsp;--profile=log:report&nbsp;program.exe</strong>
    <p>If the information about allocations is not of interest, it can be excluded:
    <p><strong>mono&nbsp;--profile=log:noalloc&nbsp;program.exe</strong>
    <p>On the other hand, if method call timing is not important, while allocations are, the needed info can be gathered with:
    <p><strong>mono&nbsp;--profile=log:nocalls&nbsp;program.exe</strong>
    <p>You will still be able to inspect information about the sequence of calls that lead to each allocation because at each object allocation a stack trace is collected if full enter/leave information is not available.
    <p>To periodically collect heap shots (and exclude method and allocation events) use the following options (making sure you run with the sgen garbage collector):
    <p><strong>mono&nbsp;--gc=sgen&nbsp;--profile=log:heapshot&nbsp;program.exe</strong>
    <p>To perform a sampling profiler run, use the <em>sample</em> option:
    <p><strong>mono&nbsp;--profile=log:sample&nbsp;program.exe</strong>
  </section>
  <section>
    <h3>Profiler option documentation</h3>
    <p>By default the <em>log</em> profiler will gather all the events provided by the Mono runtime and write them to a file named <em>output.mlpd</em>. When no option is specified, it is equivalent to using:
    <p><strong>--profile=log:calls,alloc,output=output.mlpd,maxframes=32,calldepth=100</strong>
    <p>The following options can be used to modify this default behaviour. Each option is separated from the next by a <strong>,</strong> character, with no spaces and all the options are included after the <em>log:</em> profile module specifier.
    <ul class="indent-2">
      <li><em>help</em>: display concise help info about each available option
      <li><em>[no]alloc</em>: <em>noalloc</em> disables collecting object allocation info, <em>alloc</em> enables it if it was disabled by another option like <em>heapshot</em>.
      <li><em>[no]calls</em>: <em>nocalls</em> disables collecting method enter and leave events. When this option is used at each object allocation and at some other events (like lock contentions and exception throws) a stack trace is collected by default. See the <em>maxframes</em> option to control this behaviour. <em>calls</em> enables method enter/leave events if they were disabled by another option like <em>heapshot</em>.
      <li>
        <p><em>heapshot[=MODE]</em>: collect heap shot data at each major collection. The frequency of the heap shots can be changed with the <em>MODE</em> parameter. When this option is used allocation events and method enter/leave events are not recorded by default: if they are needed, they need to be enabled explicitly. The optional parameter <em>MODE</em> can modify the default heap shot frequency. heapshot can be used multiple times with different modes: in that case a heap shot is taken if either of the conditions are met. MODE can be one of:
        <div class="indent-2">
          <ul class="indent-2">
            <li><em>NUM</em>ms: perform a heap shot if at least <em>NUM</em> milliseconds passed since the last one.
            <li><em>NUM</em>gc: perform a heap shot every <em>NUM</em> major garbage collections
            <li><em>ondemand</em>: perform a heap shot when such a command is sent to the control port
          </ul>
        </div>
      <li><em>sample[=FREQ]</em>: collect statistical samples of the program behaviour. The default is to collect a 100 times per second (100 Hz) the instruction pointer. This is equivalent to the value “100”. A value of zero for <em>FREQ</em> effectively disables sampling.
      <li><em>maxframes=NUM</em>: when a stack trace needs to be performed, collect <em>NUM</em> frames at the most. The default is 32.
      <li><em>maxsamples=NUM</em>: stop allocating reusable sample events once <em>NUM</em> events have been allocated (a value of zero for all intents and purposes means unlimited). By default, the value of this setting is the number of CPU cores multiplied by 1000. This is usually a good enough value for typical desktop and mobile apps. If you're losing too many samples due to this default (which is possible in apps with an unusually high amount of threads), you may want to tinker with this value to find a good balance between sample hit rate and performance impact on the app. The way it works is that sample events are enqueued for reuse after they're flushed to the output file; if a thread gets a sampling signal but there are no sample events in the reuse queue and the profiler has reached the maximum number of sample allocations, the sample gets dropped. So a higher number for this setting will increase the chance that a thread is able to collect a sample, but also necessarily means that there will be more work done by the profiler. You can run Mono with the <em>--stats</em> option to see statistics about sample events.
      <li><em>calldepth=NUM</em>: ignore method enter/leave events when the call chain depth is bigger than NUM.
      <li><em>zip</em>: automatically compress the output data in gzip format.
      <li>
        <p><em>output=OUTSPEC</em>: instead of writing the profiling data to the output.mlpd file, substitute <em>%p</em> in <em>OUTSPEC</em> with the current process id and <em>%t</em> with the current date and time, then do according to <em>OUTSPEC</em>:
        <div class="indent-2">
          <ul class="indent-2">
            <li>if <em>OUTSPEC</em> begins with a <em>|</em> character, execute the rest as a program and feed the data to its standard input
            <li>if <em>OUTSPEC</em> begins with a <em>-</em> character, use the rest of OUTSPEC as the filename, but force overwrite any existing file by that name
            <li>otherwise write the data the the named file: note that is a file by that name already exists, a warning is issued and profiling is disabled.
          </ul>
        </div>
      <li><em>report</em>: the profiling data is sent to mprof-report, which will print a summary report. This is equivalent to the option: <strong>output=mprof-report&nbsp;-</strong>. If the <em>output</em> option is specified as well, the report will be written to the output file instead of the console.
      <li>
        <p><em>port=PORT</em>: specify the tcp/ip port to use for the listening command server. Currently not available for windows. This server is started for example when heapshot=ondemand is used: it will read commands line by line. The following commands are available:
        <div class="indent-2">
          <ul class="indent-2">
            <li><em>heapshot</em>: perform a heapshot as soon as possible
          </ul>
        </div>
      <li><em>nocounters</em>: disables sampling of runtime and performance counters, which is normally done every 1 second.
      <li><em>coverage</em>: collect code coverage data. This implies enabling the <em>calls</em> option.
      <li><em>onlycoverage</em>: can only be used with <em>coverage</em>. This disables most other events so that the profiler mostly only collects coverage data.
    </ul>
  </section>
  <section>
    <h3>Analyzing the profile data</h3>
    <p>Currently there is a command line program (<em>mprof-report</em>) to analyze the data produced by the profiler. This is ran automatically when the <em>report</em> profiler option is used. Simply run:
    <p><strong>mprof-report&nbsp;output.mlpd</strong>
    <p>to see a summary report of the data included in the file.
  </section>
  <section>
    <h3>Trace information for events</h3>
    <p>Often it is important for some events, like allocations, lock contention and exception throws to know where they happened. Or we may want to see what sequence of calls leads to a particular method invocation. To see this info invoke mprof-report as follows:
    <p><strong>mprof-report&nbsp;--traces&nbsp;output.mlpd</strong>
    <p>The maximum number of methods in each stack trace can be specified with the <em>--maxframes=NUM</em> option:
    <p><strong>mprof-report&nbsp;--traces&nbsp;--maxframes=4&nbsp;output.mlpd</strong>
    <p>The stack trace info will be available if method enter/leave events have been recorded or if stack trace collection wasn't explicitly disabled with the <em>maxframes=0</em> profiler option.
    <p>The <em>--traces</em> option also controls the reverse reference feature in the heapshot report: for each class it reports how many references to objects of that class come from other classes.
  </section>
  <section>
    <h3>Sort order for methods and allocations</h3>
    <p>When a list of methods is printed the default sort order is based on the total time spent in the method. This time is wall clock time (that is, it includes the time spent, for example, in a sleep call, even if actual cpu time would be basically 0). Also, if the method has been ran on different threads, the time will be a sum of the time used in each thread.
    <p>To change the sort order, use the option:
    <p><strong>--method-sort=MODE</strong>
    <p>where <em>MODE</em> can be:
    <ul class="indent-2">
      <li><em>self</em>: amount of time spent in the method itself and not in its callees
      <li><em>calls</em>: the number of method invocations
      <li><em>total</em>: the total time spent in the method.
    </ul>
    <p>Object allocation lists are sorted by default depending on the total amount of bytes used by each type.
    <p>To change the sort order of object allocations, use the option:
    <p><strong>--alloc-sort=MODE</strong>
    <p>where <em>MODE</em> can be:
    <ul class="indent-2">
      <li><em>count</em>: the number of allocated objects of the given type
      <li><em>bytes</em>: the total number of bytes used by objects of the given type
    </ul>
    <p>To change the sort order of counters, use the option:
    <p><strong>--counters-sort=MODE</strong>
    <p>where <em>MODE</em> can be:
    <ul class="indent-2">
      <li><em>time</em>: sort values by time then category
      <li><em>category</em>: sort values by category then time
    </ul>
  </section>
  <section>
    <h3>Selecting what data to report</h3>
    <p>The profiler by default collects data about many runtime subsystems and mprof-report prints a summary of all the subsystems that are found in the data file. It is possible to tell mprof-report to only show information about some of them with the following option:
    <p><strong>--reports=R1[,R2...]</strong>
    <p>where the report names R1, R2 etc. can be:
    <ul class="indent-2">
      <li><em>header</em>: information about program startup and profiler version
      <li><em>jit</em>: JIT compiler information
      <li><em>sample</em>: statistical sampling information
      <li><em>gc</em>: garbage collection information
      <li><em>alloc</em>: object allocation information
      <li><em>call</em>: method profiling information
      <li><em>metadata</em>: metadata events like image loads
      <li><em>exception</em>: exception throw and handling information
      <li><em>monitor</em>: lock contention information
      <li><em>thread</em>: thread information
      <li><em>domain</em>: app domain information
      <li><em>context</em>: remoting context information
      <li><em>heapshot</em>: live heap usage at heap shots
      <li><em>counters</em>: counters samples
      <li><em>coverage</em>: code coverage data
      <li><em>stats</em>: event statistics
    </ul>
    <p>It is possible to limit some of the data displayed to a timeframe of the program execution with the option:
    <p><strong>--time=FROM-TO</strong>
    <p>where <em>FROM</em> and <em>TO</em> are seconds since application startup (they can be floating point numbers).
    <p>Another interesting option is to consider only events happening on a particular thread with the following option:
    <p><strong>--thread=THREADID</strong>
    <p>where <em>THREADID</em> is one of the numbers listed in the thread summary report (or a thread name when present).
    <p>By default long lists of methods or other information like object allocations are limited to the most important data. To increase the amount of information printed you can use the option:
    <p><strong>--verbose</strong>
  </section>
  <section>
    <h3>Track individual objects</h3>
    <p>Instead of printing the usual reports from the profiler data, it is possible to track some interesting information about some specific object addresses. The objects are selected based on their address with the <em>--track</em> option as follows:
    <p><strong>--track=0xaddr1[,0xaddr2,...]</strong>
    <p>The reported info (if available in the data file), will be class name, size, creation time, stack trace of creation (with the <em>--traces</em> option), etc. If heapshot data is available it will be possible to also track what other objects reference one of the listed addresses.
    <p>The object addresses can be gathered either from the profiler report in some cases (like in the monitor lock report), from the live application or they can be selected with the <em>--find=FINDSPEC</em> option. FINDSPEC can be one of the following:
    <ul class="indent-2">
      <li><em>S:SIZE</em>: where the object is selected if its size is at least <em>SIZE</em>
      <li><em>T:NAME</em>: where the object is selected if <em>NAME</em> partially matches its class name
    </ul>
    <p>This option can be specified multiple times with one of the different kinds of FINDSPEC. For example, the following:
    <p><strong>--find=S:10000&nbsp;--find=T:Byte[]</strong>
    <p>will find all the byte arrays that are at least 10000 bytes in size.
    <p>Note that with a moving garbage collector the object address can change, so you may need to track the changed address manually. It can also happen that multiple objects are allocated at the same address, so the output from this option can become large.
  </section>
  <section>
    <h3>Saving a profiler report</h3>
    <p>By default mprof-report will print the summary data to the console. To print it to a file, instead, use the option:
    <p><strong>--out=FILENAME</strong>
  </section>
  <section>
    <h3>Processing code coverage data</h3>
    <p>If you ran the profiler with the <em>coverage</em> option, you can process the collected coverage data into an XML file by running mprof-report like this:
    <p><strong>mprof-report --coverage-out=coverage.xml output.mlpd</strong>
  </section>
  <section>
    <h3>Dealing with profiler slowness</h3>
    <p>If the profiler needs to collect lots of data, the execution of the program will slow down significantly, usually 10 to 20 times slower. There are several ways to reduce the impact of the profiler on the program execution.
    <dl class="indent-4">
      <dt><em>Use the statistical sampling mode</em>
      <dd>
        <p>Statistical sampling allows executing a program under the profiler with minimal performance overhead (usually less than 10%). This mode allows checking where the program is spending most of its execution time without significantly perturbing its behaviour.
      <dt><em>Collect less data</em>
      <dd>
        <p>Collecting method enter/leave events can be very expensive, especially in programs that perform many millions of tiny calls. The profiler option <em>nocalls</em> can be used to avoid collecting this data or it can be limited to only a few call levels with the <em>calldepth</em> option.
        <p>Object allocation information is expensive as well, though much less than method enter/leave events. If it's not needed, it can be skipped with the <em>noalloc</em> profiler option. Note that when method enter/leave events are discarded, by default stack traces are collected at each allocation and this can be expensive as well. The impact of stack trace information can be reduced by setting a low value with the <em>maxframes</em> option or by eliminating them completely, by setting it to 0.
        <p>The other major source of data is the <em>heapshot</em> profiler option: especially if the managed heap is big, since every object needs to be inspected. The <em>MODE</em> parameter of the <em>heapshot</em> option can be used to reduce the frequency of the heap shots.
    </dl>
  </section>
  <section>
    <h3>Dealing with the size of the data files</h3>
    <p>When collecting a lot of information about a profiled program, huge data files can be generated. There are a few ways to minimize the amount of data, for example by not collecting some of the more space-consuming information or by compressing the information on the fly or by just generating a summary report.
    <dl class="indent-4">
      <dt><em>Reducing the amount of data</em>
      <dd>
        <p>Method enter/leave events can be excluded completely with the <em>nocalls</em> option or they can be limited to just a few levels of calls with the <em>calldepth</em> option. For example, the option:
        <p><strong>calldepth=10</strong>
        <p>will ignore the method events when there are more than 10 managed stack frames. This is very useful for programs that have deep recursion or for programs that perform many millions of tiny calls deep enough in the call stack. The optimal number for the calldepth option depends on the program and it needs to be balanced between providing enough profiling information and allowing fast execution speed.
        <p>Note that by default, if method events are not recorded at all, the profiler will collect stack trace information at events like allocations. To avoid gathering this data, use the <em>maxframes=0</em> profiler option.
        <p>Allocation events can be eliminated with the <em>noalloc</em> option.
        <p>Heap shot data can also be huge: by default it is collected at each major collection. To reduce the frequency, you can specify a heapshot mode: for example to collect every 5 collections (including major and minor):
        <p><strong>heapshot=5gc</strong>
        <p>or when at least 5 seconds passed since the last heap shot:
        <p><strong>heapshot=5000ms</strong>
      <dt><em>Compressing the data</em>
      <dd>
        <p>To reduce the amout of disk space used by the data, the data can be compressed either after it has been generated with the gzip command:
        <p><strong>gzip&nbsp;-9&nbsp;output.mlpd</strong>
        <p>or it can be compressed automatically by using the <em>zip</em> profiler option. Note that in this case there could be a significant slowdown of the profiled program.
        <p>The mprof-report program will tranparently deal with either compressed or uncompressed data files.
      <dt><em>Generating only a summary report</em>
      <dd>
        <p>Often it's enough to look at the profiler summary report to diagnose an issue and in this case it's possible to avoid saving the profiler data file to disk. This can be accomplished with the <em>report</em> profiler option, which will basically send the data to the mprof-report program for display.
        <p>To have more control of what summary information is reported (or to use a completely different program to decode the profiler data), the <em>output</em> profiler option can be used, with <strong>|</strong> as the first character: the rest of the output name will be executed as a program with the data fed in on the standard input.
        <p>For example, to print only the Monitor summary with stack trace information, you could use it like this:
        <p><strong>output=|mprof-report&nbsp;--reports=monitor&nbsp;--traces&nbsp;-</strong>
    </dl>
  </section>
</section>
<section>
  <h2>WEB SITE</h2>
  <p>http://www.mono-project.com/docs/debug+profile/profile/profiler/
</section>
<section>
  <h2>SEE ALSO</h2>
  <p>mono(1)
</section>
<section>
  <h2>AUTHORS</h2>
  <p>Paolo Molaro, Alex Rønne Petersen
</section>

